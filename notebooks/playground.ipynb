{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.stats import norm, halfnorm, uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import bayesflow as beef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "# from priors import sample_mrw_eta, sample_mixture_random_walk\n",
    "from priors import sample_rw_eta, sample_random_walk\n",
    "from likelihood import sample_softmax_rl\n",
    "from context import generate_context\n",
    "from configurator import configure_input\n",
    "from helpers import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "# Configure rng\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NETWORK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PARAM_LABELS = (\"Learning rate\", \"Sensitivity\")\n",
    "LOCAL_PARAM_NAMES = (r\"$\\alpha$\", r\"$\\tau$\")\n",
    "# GLOBAL_PARAM_LABELS = (\"Standard deviation\", \"Standard deviation\", \"Switch probability\")\n",
    "# GLOBAL_PARAM_NAMES = (r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\tau}$\", r\"$\\rho_{\\alpha}$\", r\"$\\rho_{\\tau}$\")\n",
    "\n",
    "FONT_SIZE_1 = 22\n",
    "FONT_SIZE_2 = 18\n",
    "FONT_SIZE_3 = 16\n",
    "\n",
    "# GLOBAL_PRIOR_MEAN = np.concatenate(\n",
    "#     [\n",
    "#         halfnorm(0, [0.05, 3]).mean().round(decimals=2),\n",
    "#         uniform(0, [0.1, 0.1]).mean().round(decimals=2)\n",
    "#     ]\n",
    "# )\n",
    "# GLOBAL_PRIOR_STD = np.concatenate(\n",
    "#     [\n",
    "#         halfnorm(0, [0.05, 3]).std().round(decimals=2),\n",
    "#         uniform(0, [0.1, 0.1]).std().round(decimals=2)\n",
    "#     ]\n",
    "# )\n",
    "# LOCAL_PRIOR_MEAN = np.array([0.5, 37])\n",
    "# LOCAL_PRIOR_STD = np.array([0.3, 24])\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Empiric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = pd.read_csv(\"../data/data_fontanesi_prep.csv\")\n",
    "emp_data.f_cor = emp_data.f_cor / 60\n",
    "emp_data.f_inc = emp_data.f_inc / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplar Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta = sample_mrw_eta()\n",
    "# theta = sample_mixture_random_walk(eta)\n",
    "eta = sample_rw_eta()\n",
    "theta = sample_random_walk(eta)\n",
    "time = np.arange(theta.shape[0])\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(10, 3))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta[:, i],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} ({LOCAL_PARAM_NAMES[i]})', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time step\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior = beef.simulation.TwoLevelPrior(\n",
    "#     hyper_prior_fun=sample_mrw_eta,\n",
    "#     local_prior_fun=sample_mixture_random_walk,\n",
    "# )\n",
    "prior = beef.simulation.TwoLevelPrior(\n",
    "    hyper_prior_fun=sample_rw_eta,\n",
    "    local_prior_fun=sample_random_walk,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = prior(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_PRIOR_MEAN = np.round(prior_samples['hyper_parameters'].mean(axis=0), 2)\n",
    "GLOBAL_PRIOR_STD = np.round(prior_samples['hyper_parameters'].std(axis=0), 2)\n",
    "LOCAL_PRIOR_MEAN = np.array([0.5, 18])\n",
    "LOCAL_PRIOR_STD = np.array([0.3, 19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = beef.simulation.ContextGenerator(\n",
    "    batchable_context_fun=generate_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = beef.simulation.Simulator(\n",
    "    simulator_fun=sample_softmax_rl,\n",
    "    context_generator=context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = beef.simulation.TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=likelihood,\n",
    "    name=\"non-stationary_softmax_rl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator_settings = {\n",
    "    \"lstm1_hidden_units\": 512,\n",
    "    \"lstm2_hidden_units\": 256,\n",
    "    \"lstm3_hidden_units\": 128,\n",
    "    \"trainer\": {\n",
    "        \"max_to_keep\": 1,\n",
    "        \"default_lr\": 5e-4,\n",
    "        \"memory\": False,\n",
    "    },\n",
    "    \"local_amortizer_settings\": {\n",
    "        \"num_coupling_layers\": 8,\n",
    "        \"coupling_design\": 'interleaved'\n",
    "    },\n",
    "    \"global_amortizer_settings\": {\n",
    "        \"num_coupling_layers\": 6,\n",
    "        \"coupling_design\": 'interleaved'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = beef.networks.HierarchicalNetwork(\n",
    "    [\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm1_hidden_units\"], return_sequences=True)),\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm2_hidden_units\"], return_sequences=True)),\n",
    "            ]\n",
    "        ),\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm3_hidden_units\"]))\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=2,\n",
    "        **approximator_settings.get(\"local_amortizer_settings\")\n",
    "    )\n",
    ")\n",
    "global_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=2,\n",
    "        **approximator_settings.get(\"global_amortizer_settings\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = beef.amortizers.TwoLevelAmortizedPosterior(\n",
    "    local_amortizer=local_network,\n",
    "    global_amortizer=global_network,\n",
    "    summary_net=summary_network\n",
    ")\n",
    "trainer = beef.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configure_input,\n",
    "    **approximator_settings.get(\"trainer\"),\n",
    "    checkpoint_path=\"../checkpoints/rw__rl_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TRAIN_NETWORK:\n",
    "    history = trainer.train_online(\n",
    "        epochs=200,\n",
    "        iterations_per_epoch=1000,\n",
    "        batch_size=32\n",
    "    )\n",
    "    loss_plot = beef.diagnostics.plot_losses(trainer.loss_history.get_plottable())\n",
    "else:\n",
    "    loss_plot = beef.diagnostics.plot_losses(trainer.loss_history.get_plottable())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = model(1)\n",
    "theta_true = val_data['local_prior_draws'][0]\n",
    "eta_true = val_data['hyper_prior_draws'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_config = configure_input(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sample = amortizer.sample(val_data_config, n_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post = post_sample['local_samples'] * LOCAL_PRIOR_STD + LOCAL_PRIOR_MEAN\n",
    "theta_post_mean = theta_post.mean(axis=1)\n",
    "theta_post_std = theta_post.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(theta_post_mean.shape[0])\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(10, 3))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta_post_mean[:, i],\n",
    "        color='maroon', label=\"Posterior\"\n",
    "    )\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta_true[:, i],\n",
    "        color='black', label=\"True parameter\"\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        time,\n",
    "        theta_post_mean[:, i] - theta_post_std[:, i],\n",
    "        theta_post_mean[:, i] + theta_post_std[:, i],\n",
    "        color='maroon', alpha=0.5, linewidth=0.0\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} ({LOCAL_PARAM_NAMES[i]})', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "        fig.subplots_adjust(hspace=0.5)\n",
    "        fig.legend(fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05), loc=\"center\", ncol=2)\n",
    "    ax.set_xlabel(\"Time step\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"../plots/recovered_theta.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_post = post_sample['global_samples'] * GLOBAL_PRIOR_STD + GLOBAL_PRIOR_MEAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = prior(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_eta = prior_samples['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(10, 3))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.axvline(\n",
    "        eta_true[i],\n",
    "        color='black',\n",
    "        lw=3,\n",
    "        label=\"True parameter\"\n",
    "    )\n",
    "    sns.histplot(\n",
    "        eta_post[:, i],\n",
    "        color='maroon',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "        label=\"Posterior\"\n",
    "    )\n",
    "\n",
    "    sns.histplot(\n",
    "        prior_eta[:, i],\n",
    "        ax=ax,\n",
    "        alpha=0.25,\n",
    "        linewidth=0,\n",
    "        label=\"Prior\"\n",
    "    )\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    ax.set_ylabel(\"\", fontsize=FONT_SIZE_2)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Count\", fontsize=FONT_SIZE_2)\n",
    "        fig.subplots_adjust(hspace=0.5)\n",
    "        fig.legend(fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05), loc=\"center\", ncol=3)\n",
    "    ax.set_xlabel(f'{GLOBAL_PARAM_LABELS[i]} ({GLOBAL_PARAM_NAMES[i]})', fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"../plots/recovered_eta.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to Empirical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 2000\n",
    "# SUBJECTS = emp_data.id.unique()\n",
    "RELEVANT_SUB = np.array([1, 3, 5, 6, 7, 8, 16, 20, 22, 23, 24, 26, 27])\n",
    "theta_post = np.zeros((len(RELEVANT_SUB), 240, N_SAMPLES, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sub in enumerate(tqdm(RELEVANT_SUB)):\n",
    "    person_data = emp_data.loc[emp_data.id == sub][['resp', 'f_cor', 'f_inc', 'cor_option', 'inc_option']].to_numpy()\n",
    "    resp = person_data[:, 0, None]\n",
    "    feedback = person_data[:, 1:3]\n",
    "    cor_option = person_data[:, 3, None]\n",
    "    inc_option = person_data[:, 4, None]\n",
    "    data = np.c_[\n",
    "        resp, feedback, to_categorical(cor_option), to_categorical(inc_option)\n",
    "    ]\n",
    "    post_sample = amortizer.sample({'summary_conditions': data[None, :, :]}, n_samples=N_SAMPLES)\n",
    "    theta_post[i] = post_sample['local_samples'] * LOCAL_PRIOR_STD + LOCAL_PRIOR_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_means = np.mean(theta_post, axis=2)\n",
    "post_std = np.std(theta_post, axis=2)\n",
    "post_means_mean = np.mean(post_means, axis=0)\n",
    "post_means_std = np.std(post_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(post_means_mean.shape[0])\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 3.5))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        post_means_mean[:, i],\n",
    "        color='maroon', label=\"Posterior\"\n",
    "    )\n",
    "    ax.fill_between( \n",
    "        time,\n",
    "        post_means_mean[:, i] - post_means_std[:, i],\n",
    "        post_means_mean[:, i] + post_means_std[:, i],\n",
    "        color='maroon', alpha=0.5, linewidth=0.0\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} ({LOCAL_PARAM_NAMES[i]})', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    xticks = np.arange(0, 240+1, 40)\n",
    "    xticks[0] = 1\n",
    "    ax.set_xticks(xticks)\n",
    "    if i == 0:\n",
    "        ax.set_yticks(np.arange(0, 0.7, 0.2))\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "        # fig.subplots_adjust(hspace=0.5)\n",
    "        # fig.legend(fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05), loc=\"center\", ncol=2)\n",
    "    if i == 1:\n",
    "        ax.set_yticks(np.arange(0, 51, 15))\n",
    "    ax.set_xlabel(\"Trial\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/inferred_trajectories.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SIM = 200\n",
    "NUM_SAMPLES = 1000\n",
    "TIME_POINTS = [39, 80, 120, 159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = model(NUM_SIM)\n",
    "theta_true = sim_data['local_prior_draws']\n",
    "eta_true = sim_data['hyper_prior_draws']\n",
    "sim_data_config = trainer.configurator(sim_data)['summary_conditions']\n",
    "sim_data_config.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post = np.zeros((NUM_SIM, 240, NUM_SAMPLES, 2))\n",
    "eta_post = np.zeros((NUM_SIM, NUM_SAMPLES, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(NUM_SIM)):\n",
    "    post_samples = amortizer.sample({'summary_conditions': sim_data_config[i][None, :, :]}, n_samples=NUM_SAMPLES)\n",
    "    theta_post[i] = post_samples['local_samples']\n",
    "    eta_post[i] = post_samples['global_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/local_post.npy', theta_post)\n",
    "# np.save('../data/global_post.npy', eta_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post = theta_post * LOCAL_PRIOR_STD + LOCAL_PRIOR_MEAN\n",
    "eta_post = eta_post * GLOBAL_PRIOR_STD + GLOBAL_PRIOR_MEAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post_mean = theta_post.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_post_mean[TIME_POINTS[0], :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(8, 16))\n",
    "\n",
    "# create 4x1 subfigs\n",
    "subfigs = fig.subfigures(nrows=4, ncols=1)\n",
    "for row, subfig in enumerate(subfigs):\n",
    "    subfig.suptitle(f\"T = {TIME_POINTS[row] + 1}\", fontsize=FONT_SIZE_1, fontweight='semibold')\n",
    "\n",
    "    # create 1x3 subplots per subfig\n",
    "    axs = subfig.subplots(nrows=1, ncols=2)\n",
    "    for col, ax in enumerate(axs):\n",
    "        ax.scatter(\n",
    "            theta_true[:, TIME_POINTS[row], col],\n",
    "            theta_post_mean[:, TIME_POINTS[row], col],\n",
    "            alpha=0.5, color=\"maroon\"\n",
    "            )\n",
    "        \n",
    "        # Make plots quadratic to avoid visual illusions\n",
    "        lower = min(theta_true[:, TIME_POINTS[row], col].min(),\n",
    "                    theta_post_mean[:, TIME_POINTS[row], col].min())\n",
    "        upper = max(theta_true[:, TIME_POINTS[row], col].max(),\n",
    "                    theta_post_mean[:, TIME_POINTS[row], col].max())\n",
    "        eps = (upper - lower) * 0.1\n",
    "        ax.set_xlim([lower - eps, upper + eps])\n",
    "        ax.set_ylim([lower - eps, upper + eps])\n",
    "        ax.plot(\n",
    "            [ax.get_xlim()[0], ax.get_xlim()[1]],\n",
    "            [ax.get_ylim()[0], ax.get_ylim()[1]],\n",
    "            color=\"black\",\n",
    "            alpha=0.9,\n",
    "            linestyle=\"dashed\",\n",
    "        )\n",
    "\n",
    "        r2 = r2_score(\n",
    "            theta_true[:, TIME_POINTS[row], col],\n",
    "            theta_post_mean[:, TIME_POINTS[row], col]\n",
    "        )\n",
    "        ax.text(\n",
    "            0.1, 0.9,\n",
    "            \"$R^2$ = {:.3f}\".format(r2),\n",
    "            horizontalalignment=\"left\",\n",
    "            verticalalignment=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "            size=FONT_SIZE_3,\n",
    "        )\n",
    "        corr = np.corrcoef(\n",
    "            theta_true[:, TIME_POINTS[row], col],\n",
    "            theta_post_mean[:, TIME_POINTS[row], col]\n",
    "        )[0, 1]\n",
    "        ax.text(\n",
    "            0.1, 0.8,\n",
    "            \"$r$ = {:.3f}\".format(corr),\n",
    "            horizontalalignment=\"left\", \n",
    "            verticalalignment=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "            size=FONT_SIZE_3,\n",
    "        )\n",
    "\n",
    "        if row == 0:\n",
    "            ax.set_title(LOCAL_PARAM_LABELS[col] + ' ({})'.format(LOCAL_PARAM_NAMES[col]), fontsize=FONT_SIZE_2)\n",
    "        if row == 3:\n",
    "            ax.set_xlabel(\"Ground truth\", fontsize=FONT_SIZE_2)\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Estimated\", fontsize=FONT_SIZE_2)\n",
    "        #     ax.set_xticks([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "        #     ax.set_yticks([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "        #     if row > 1:\n",
    "        #         ax.set_xticks([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "        #         ax.set_yticks([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "        # if col == 1:\n",
    "        #     ax.set_xticks([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "        #     ax.set_yticks([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "        # if col == 2:\n",
    "        #     ax.set_xticks([0.0, 0.5, 1, 1.5])\n",
    "        #     ax.set_yticks([0.0, 0.5, 1, 1.5])\n",
    "        # Prettify\n",
    "        ax.grid(alpha=0.5)\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONT_SIZE_3)\n",
    "        ax.tick_params(axis=\"both\", which=\"minor\", labelsize=FONT_SIZE_3)\n",
    "\n",
    "sns.despine()\n",
    "# fig.tight_layout()\n",
    "plt.savefig('../plots/param_recovery.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Re-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RESIM = 1000\n",
    "BIN_IDX = np.arange(0, 240, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_resim_data = np.zeros((len(RELEVANT_SUB), NUM_RESIM, 240, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sub in enumerate(tqdm(RELEVANT_SUB)):\n",
    "    person_data = emp_data.loc[emp_data.id == sub][['resp', 'f_cor', 'f_inc', 'cor_option', 'inc_option']].to_numpy()\n",
    "    feedback = person_data[:, 1:3]\n",
    "    cor_option = person_data[:, 3, None]\n",
    "    inc_option = person_data[:, 4, None]\n",
    "    context = np.c_[\n",
    "        feedback, cor_option, inc_option\n",
    "    ]\n",
    "\n",
    "    idx = np.random.choice(np.arange(N_SAMPLES), size=NUM_RESIM, replace=False)\n",
    "    for j in range(NUM_RESIM):\n",
    "        current_params = theta_post[i, :, idx[j], :]\n",
    "        post_resim_data[i, j, :, 0] = sample_softmax_rl(current_params, context)\n",
    "        post_resim_data[i, j, :, 1] = (post_resim_data[i, j, :, 0] == cor_option[:, 0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_accuracy = np.zeros((NUM_RESIM, len(BIN_IDX), 1))\n",
    "pred_accuracy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_RESIM):\n",
    "    for l, bin in enumerate(bin_idx):\n",
    "        pred_accuracy[i, l, 0] = post_resim_data[:, i, bin:bin+5, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_correct = np.zeros((13, 240, 1))\n",
    "for i, sub in enumerate(RELEVANT_SUB):\n",
    "    emp_correct[i, :] =  emp_data.loc[emp_data.id == sub][['correct']].to_numpy()\n",
    "emp_correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, bin in enumerate(bin_idx):\n",
    "    emp_accuracy[l, 0] = emp_correct[:, bin:bin+5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred_acc = pred_accuracy.mean(axis=0)\n",
    "std_pred_acc = pred_accuracy.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pred_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = np.arange(len(BIN_IDX))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.grid(alpha=0.5)\n",
    "ax.plot(\n",
    "    trials,\n",
    "    emp_accuracy,\n",
    "    color='black', label=\"Empricial\"\n",
    ")\n",
    "ax.plot(\n",
    "    trials,\n",
    "    mean_pred_acc,\n",
    "    color='maroon', label=\"Re-simulated\"\n",
    ")\n",
    "ax.fill_between( \n",
    "    trials,\n",
    "    mean_pred_acc[:, 0] - std_pred_acc[:, 0],\n",
    "    mean_pred_acc[:, 0] + std_pred_acc[:, 0],\n",
    "    color='maroon', alpha=0.5, linewidth=0.0\n",
    ")\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3+1)\n",
    "ax.set_xticks(trials[0::4], labels=BIN_IDX[0::4])\n",
    "ax.set_ylabel(\"Accuracy\", fontsize=FONT_SIZE_2+4, labelpad=10)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "fig.legend(fontsize=FONT_SIZE_2+4, bbox_to_anchor=(0.5, -0.05), loc=\"center\", ncol=2)\n",
    "ax.set_xlabel(\"Trial\", fontsize=FONT_SIZE_2+4, labelpad=10)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/post_resim_accuracy_bin.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.stats import norm, halfnorm, uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import bayesflow as beef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from priors import sample_eta, sample_theta_t\n",
    "from context import generate_context\n",
    "from likelihood import sample_softmax_rl\n",
    "from configurator import configure_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "# Configure rng\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NETWORK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA_NAMES = (\"Learning rate\", \"Sensitivity\")\n",
    "THETA_LABELS= (r\"$\\alpha$\", r\"$\\tau$\")\n",
    "\n",
    "# plotting\n",
    "FONT_SIZE_1 = 22\n",
    "FONT_SIZE_2 = 18\n",
    "FONT_SIZE_3 = 16\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = sample_eta()\n",
    "theta = sample_theta_t(eta)\n",
    "time = np.arange(theta.shape[0])\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(14, 4))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta[:, i],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.set_title(f'{THETA_NAMES[i]} ({THETA_LABELS[i]})', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time step\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = beef.simulation.TwoLevelPrior(\n",
    "    hyper_prior_fun=sample_eta,\n",
    "    local_prior_fun=sample_theta_t,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_gen = beef.simulation.ContextGenerator(\n",
    "    batchable_context_fun=generate_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = context_gen(1)['batchable_context'][0]\n",
    "eta = sample_eta()\n",
    "theta = sample_theta_t(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = beef.simulation.Simulator(\n",
    "    simulator_fun=sample_softmax_rl,\n",
    "    context_generator=context_gen,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = beef.simulation.TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=likelihood,\n",
    "    name=\"non-stationary_rl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator_settings = {\n",
    "    \"lstm1_hidden_units\": 512,\n",
    "    \"lstm2_hidden_units\": 256,\n",
    "    \"lstm3_hidden_units\": 128,\n",
    "    \"trainer\": {\n",
    "        \"max_to_keep\": 1,\n",
    "        \"default_lr\": 5e-4,\n",
    "        \"memory\": False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = beef.networks.HierarchicalNetwork(\n",
    "    [\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm1_hidden_units\"], return_sequences=True)),\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm2_hidden_units\"], return_sequences=True)),\n",
    "            ]\n",
    "        ),\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm3_hidden_units\"]))\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=2,\n",
    "        num_coupling_layers=8,\n",
    "        coupling_settings={\n",
    "            \"dense_args\": dict(kernel_regularizer=None),\n",
    "            \"dropout\": False,\n",
    "            \"coupling_design\": 'interleaved'\n",
    "        }\n",
    "    )\n",
    ")\n",
    "global_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=4,\n",
    "        num_coupling_layers=6,\n",
    "        coupling_settings={\n",
    "            \"dense_args\": dict(kernel_regularizer=None),\n",
    "            \"dropout\": False,\n",
    "            \"coupling_design\": 'interleaved'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = beef.amortizers.TwoLevelAmortizedPosterior(\n",
    "    local_amortizer=local_network,\n",
    "    global_amortizer=global_network,\n",
    "    summary_net=summary_network\n",
    ")\n",
    "trainer = beef.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configure_input,\n",
    "    **approximator_settings.get(\"trainer\"),\n",
    "    checkpoint_path=\"../checkpoints/reversal_learning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NETWORK:\n",
    "    history = trainer.train_online(\n",
    "        epochs=200,\n",
    "        iterations_per_epoch=1000,\n",
    "        batch_size=32\n",
    "    )\n",
    "else:\n",
    "    history = trainer.loss_history.get_plottable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = beef.diagnostics.plot_losses(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

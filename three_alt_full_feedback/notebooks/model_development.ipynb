{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.stats import norm, halfnorm, uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import bayesflow as beef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from priors import sample_eta, sample_random_walk\n",
    "from model import sample_softmax_rl\n",
    "from context import generate_context\n",
    "from configurator import configure_input\n",
    "from helpers import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "# Configure rng\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NETWORK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "THETA_NAMES = (\"Learning rate\", \"Learning rate\", \"Sensitivity\")\n",
    "THETA_LABELS= (r\"$\\alpha_{\\text{selected}}$\", r\"$\\alpha_{\\text{unselected}}$\", r\"$\\tau$\")\n",
    "ETA_NAMES = (\"Transition scale\", \"Transition scale\", \"Transition scale\")\n",
    "ETA_LABELS= (r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\tau}$\")\n",
    "\n",
    "# plotting\n",
    "FONT_SIZE_1 = 22\n",
    "FONT_SIZE_2 = 18\n",
    "FONT_SIZE_3 = 16\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "\n",
    "# analysis\n",
    "NUM_VALIDATION_SIM = 400\n",
    "NUM_SAMPLES = 500\n",
    "NUM_RESIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/empiric_data.csv\")\n",
    "NUM_SUBJECTS = len(np.unique(data.participant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplar Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = sample_eta()\n",
    "theta = sample_random_walk(eta)\n",
    "time = np.arange(theta.shape[0])\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(14, 4))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta[:, i],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.set_title(f'{THETA_NAMES[i]} ({THETA_LABELS[i]})', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time step\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = beef.simulation.TwoLevelPrior(\n",
    "    hyper_prior_fun=sample_eta,\n",
    "    local_prior_fun=sample_random_walk,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_PRIOR_MEAN = np.array([0.02, 0.02, 0.8])\n",
    "GLOBAL_PRIOR_STD = np.array([0.01, 0.01, 0.6])\n",
    "LOCAL_PRIOR_MEAN = np.array([0.4, 0.4, 5.7])\n",
    "LOCAL_PRIOR_STD = np.array([0.25, 0.25, 7.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = beef.simulation.ContextGenerator(\n",
    "    batchable_context_fun=generate_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = beef.simulation.Simulator(\n",
    "    simulator_fun=sample_softmax_rl,\n",
    "    context_generator=context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the non-stationary_softmax_rl model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 200, 3)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 200)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 3)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 200, 3)\n",
      "INFO:root:No shared_prior_draws provided.\n",
      "INFO:root:Could not determine shape of simulation batchable context. Type appears to be non-array: <class 'list'>,                                    so make sure your input configurator takes care of that!\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n"
     ]
    }
   ],
   "source": [
    "model = beef.simulation.TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=likelihood,\n",
    "    name=\"non-stationary_softmax_rl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator_settings = {\n",
    "    \"lstm1_hidden_units\": 512,\n",
    "    \"lstm2_hidden_units\": 256,\n",
    "    \"lstm3_hidden_units\": 128,\n",
    "    \"trainer\": {\n",
    "        \"max_to_keep\": 1,\n",
    "        \"default_lr\": 5e-4,\n",
    "        \"memory\": False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = beef.networks.HierarchicalNetwork(\n",
    "    [\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm1_hidden_units\"], return_sequences=True)),\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm2_hidden_units\"], return_sequences=True)),\n",
    "            ]\n",
    "        ),\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm3_hidden_units\"]))\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=3,\n",
    "        num_coupling_layers=8,\n",
    "        coupling_settings={\n",
    "            \"dense_args\": dict(kernel_regularizer=None),\n",
    "            \"dropout\": False,\n",
    "            \"coupling_design\": 'interleaved'\n",
    "        }\n",
    "    )\n",
    ")\n",
    "global_network = beef.amortizers.AmortizedPosterior(\n",
    "    beef.networks.InvertibleNetwork(\n",
    "        num_params=3,\n",
    "        num_coupling_layers=6,\n",
    "        coupling_settings={\n",
    "            \"dense_args\": dict(kernel_regularizer=None),\n",
    "            \"dropout\": False,\n",
    "            \"coupling_design\": 'interleaved'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "amortizer = beef.amortizers.TwoLevelAmortizedPosterior(\n",
    "    local_amortizer=local_network,\n",
    "    global_amortizer=global_network,\n",
    "    summary_net=summary_network\n",
    ")\n",
    "trainer = beef.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configure_input,\n",
    "    **approximator_settings.get(\"trainer\"),\n",
    "    checkpoint_path=\"../checkpoints/three_alt_full_feed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NETWORK:\n",
    "    history = trainer.train_online(\n",
    "        epochs=200,\n",
    "        iterations_per_epoch=1000,\n",
    "        batch_size=32\n",
    "    )\n",
    "else:\n",
    "    history = trainer.loss_history.get_plottable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = beef.diagnostics.plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200, 6)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model(1)\n",
    "_ = configure_input(x)\n",
    "_['summary_conditions'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
